{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m9rYjdUaNnt"
      },
      "source": [
        "**ძირითადი ნაწილი (6 ქულა)**\n",
        "\n",
        "ამ დავალების პირობა თქვენთვის კარგად ნაცნობია შუალედური გამოცდიდან. 😁😁 მოგიწევთ, რომ იდენტური ამოცანა ამოხსნათ, ოღონდ PySpark-ის გამოყენებით. არ გამოიყენოთ Pandas-ის ბიბლიოთეკა. წინააღმდეგ შემთხვევაში არ ჩაითვლება. \n",
        "\n",
        "შეგახსენებთ პირობას:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPk_kX-TaNn0"
      },
      "source": [
        "\n",
        "You are given dataset of Marvel superheroes (some DC heroes may have sneaked through as usual), your first task is to randomly generate teams of 5 heroes with following columns:\n",
        "- team_name: team name should be generated using strongest hero name in team with following template \"Team: {Strongest_Hero_Name}\" to calculate stongest hero in team you'll need to calculate average of following attributes in charcters_stats file: Intelligence, Strength, Speed, Durability, Power, Combat\n",
        "- leader: name of hero with highest Intelligence score in team\n",
        "- tank: name of hero with highest sum value of Strength and Durability\n",
        "- damage: hero with highest sum value of Speed, Power and Combat \n",
        "- the_other_guy: one of the hero who's not specified in above columns\n",
        "- the_other_guy2: one of the hero who's not specified in above columns\n",
        "- top_average_speed: average of top 3 highest speed entries in team\n",
        "- top_average_height: average of top 3 tallest heroes in team\n",
        "- flight_count: number of heroes who can fly in team (available in superheroes_power_matrix)  \n",
        "\n",
        "**same hero should not end up in multiple teams.**\n",
        "\n",
        "**all negative values should be converted to 0.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnDE6zofaNn3",
        "outputId": "deaa8ea1-b3f6-46c4-b25f-e78c38952c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [73.9 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [833 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n",
            "Hit:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,821 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,452 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,230 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.6 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.9 kB]\n",
            "Fetched 13.8 MB in 7s (1,929 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs icedtea-8-plugin libnss-mdns fonts-ipafont-gothic fonts-ipafont-mincho\n",
            "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 13 newly installed, 0 to remove and 82 not upgraded.\n",
            "Need to get 33.6 MB of archives.\n",
            "After this operation, 122 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u312-b07-0ubuntu1~18.04 [28.2 MB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u312-b07-0ubuntu1~18.04 [69.6 kB]\n",
            "Fetched 33.6 MB in 5s (7,092 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../11-openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../12-openjdk-8-jre_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libhawtjni-runtime-java libjansi-java libjansi-native-java libjline2-java\n",
            "  scala-library scala-parser-combinators scala-xml\n",
            "Suggested packages:\n",
            "  scala-doc\n",
            "The following NEW packages will be installed:\n",
            "  libhawtjni-runtime-java libjansi-java libjansi-native-java libjline2-java\n",
            "  scala scala-library scala-parser-combinators scala-xml\n",
            "0 upgraded, 8 newly installed, 0 to remove and 82 not upgraded.\n",
            "Need to get 25.0 MB of archives.\n",
            "After this operation, 28.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libhawtjni-runtime-java all 1.15-2 [27.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjansi-native-java all 1.7-1 [19.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjansi-java all 1.16-1 [36.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjline2-java all 2.14.6-1 [150 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 scala-library all 2.11.12-4~18.04 [9,589 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 scala-parser-combinators all 1.0.3-3 [355 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 scala-xml all 1.0.3-3 [601 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 scala all 2.11.12-4~18.04 [14.2 MB]\n",
            "Fetched 25.0 MB in 4s (5,716 kB/s)\n",
            "Selecting previously unselected package libhawtjni-runtime-java.\n",
            "(Reading database ... 155673 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libhawtjni-runtime-java_1.15-2_all.deb ...\n",
            "Unpacking libhawtjni-runtime-java (1.15-2) ...\n",
            "Selecting previously unselected package libjansi-native-java.\n",
            "Preparing to unpack .../1-libjansi-native-java_1.7-1_all.deb ...\n",
            "Unpacking libjansi-native-java (1.7-1) ...\n",
            "Selecting previously unselected package libjansi-java.\n",
            "Preparing to unpack .../2-libjansi-java_1.16-1_all.deb ...\n",
            "Unpacking libjansi-java (1.16-1) ...\n",
            "Selecting previously unselected package libjline2-java.\n",
            "Preparing to unpack .../3-libjline2-java_2.14.6-1_all.deb ...\n",
            "Unpacking libjline2-java (2.14.6-1) ...\n",
            "Selecting previously unselected package scala-library.\n",
            "Preparing to unpack .../4-scala-library_2.11.12-4~18.04_all.deb ...\n",
            "Unpacking scala-library (2.11.12-4~18.04) ...\n",
            "Selecting previously unselected package scala-parser-combinators.\n",
            "Preparing to unpack .../5-scala-parser-combinators_1.0.3-3_all.deb ...\n",
            "Unpacking scala-parser-combinators (1.0.3-3) ...\n",
            "Selecting previously unselected package scala-xml.\n",
            "Preparing to unpack .../6-scala-xml_1.0.3-3_all.deb ...\n",
            "Unpacking scala-xml (1.0.3-3) ...\n",
            "Selecting previously unselected package scala.\n",
            "Preparing to unpack .../7-scala_2.11.12-4~18.04_all.deb ...\n",
            "Unpacking scala (2.11.12-4~18.04) ...\n",
            "Setting up scala-parser-combinators (1.0.3-3) ...\n",
            "Setting up libhawtjni-runtime-java (1.15-2) ...\n",
            "Setting up scala-library (2.11.12-4~18.04) ...\n",
            "Setting up scala-xml (1.0.3-3) ...\n",
            "Setting up libjansi-native-java (1.7-1) ...\n",
            "Setting up libjansi-java (1.16-1) ...\n",
            "Setting up libjline2-java (2.14.6-1) ...\n",
            "Setting up scala (2.11.12-4~18.04) ...\n",
            "update-alternatives: using /usr/share/scala-2.11/bin/scala to provide /usr/bin/scala (scala) in auto mode\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j\n",
            "Successfully installed py4j-0.10.9.3\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "\n",
        "!apt-get install openjdk-8-jre\n",
        "\n",
        "!apt-get install scala\n",
        "!pip install py4j\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.8-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kVb40Xmvqk2p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.8-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"Test Setup\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "phVKCr88jjoZ"
      },
      "outputs": [],
      "source": [
        "df_stats = spark.read.option(\"header\", True).csv(\"character_stats.csv\").drop('Alignment', 'Total')\n",
        "df_info = spark.read.option(\"header\", True).csv(\"marvel_characters_info.csv\").select('Name', 'Height')\n",
        "df_power_matrix = spark.read.option(\"header\", True).csv(\"superheroes_power_matrix.csv\").select('Name', 'Flight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HChRXrK7jy7v"
      },
      "outputs": [],
      "source": [
        "df_tmp = df_stats.join(df_info,'Name', 'full')\n",
        "df = df_tmp.join(df_power_matrix, 'Name', 'full')\n",
        "\n",
        "del df_stats\n",
        "del df_info\n",
        "del df_power_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8WCvs4SuyjJ4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "df = df.withColumn(\"Intelligence\", df.Intelligence.cast(DoubleType()))\\\n",
        "  .withColumn(\"Strength\", df.Strength.cast(DoubleType()))\\\n",
        "  .withColumn(\"Speed\", df.Speed.cast(DoubleType()))\\\n",
        "  .withColumn(\"Durability\", df.Durability.cast(DoubleType()))\\\n",
        "  .withColumn(\"Power\", df.Power.cast(DoubleType()))\\\n",
        "  .withColumn(\"Combat\", df.Combat.cast(DoubleType()))\\\n",
        "  .withColumn(\"Height\", df.Height.cast(DoubleType()))\\\n",
        "  .withColumn(\"Flight\", df.Flight.cast(BooleanType()))\\\n",
        "\n",
        "\n",
        "df = df.withColumn(\"Flight\", df.Flight.cast(IntegerType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DPORwdYqANUL"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(returnType=DoubleType())\n",
        "def filter_negative(stat):\n",
        "     return None if stat == None else max(0.0, stat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f5w5OC56_D-x"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"Intelligence\", filter_negative(df.Intelligence))\\\n",
        "  .withColumn(\"Strength\", filter_negative(df.Strength))\\\n",
        "  .withColumn(\"Speed\", filter_negative(df.Speed))\\\n",
        "  .withColumn(\"Durability\", filter_negative(df.Durability))\\\n",
        "  .withColumn(\"Power\", filter_negative(df.Power))\\\n",
        "  .withColumn(\"Combat\", filter_negative(df.Combat))\\\n",
        "  .withColumn(\"Height\", filter_negative(df.Height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_ajyxXKGBhZ4"
      },
      "outputs": [],
      "source": [
        "df = df.dropDuplicates(['Name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nXZtSIXqB2q4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import rand \n",
        "\n",
        "df_randomized = df.orderBy(rand())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "32NrY3fIMXrA"
      },
      "outputs": [],
      "source": [
        "count = df_randomized.count()\n",
        "df = df_randomized.limit(count - count%5)\n",
        "del df_randomized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3gZ32wWQKQcV"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import array, lit\n",
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "from pyspark.sql import Window\n",
        "\n",
        "num_teams = df.count() // 5\n",
        "teams = list(range(num_teams)) * 5\n",
        "team_df = spark.createDataFrame(teams, IntegerType()).withColumnRenamed(\"value\", \"group_number\")\n",
        "\n",
        "# df.withColumn(\"row_idx\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "# other idea: apply func to df which maps each row_idx to floor multiple of 5 (x - x%5)\n",
        "a = df.withColumn(\"row_idx\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "b = team_df.withColumn(\"row_idx\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "team_df = team_df.limit(df.count() // 5)\n",
        "\n",
        "df = a.join(b, a.row_idx == b.row_idx).\\\n",
        "             drop(\"row_idx\")\n",
        "\n",
        "del num_teams\n",
        "del teams\n",
        "del team_df\n",
        "del a\n",
        "del b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oVSxuyo8nRAd"
      },
      "outputs": [],
      "source": [
        "df = df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LTQ9bZU2iGdo"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import lit, col\n",
        "\n",
        "df = df.withColumn(\"avg_total\", (col('Intelligence') + col('Strength') + col('Speed') + col('Durability') + col('Power') + col('Combat')) / lit(6))\n",
        "df = df.withColumn(\"tankiness\", col('Strength') + col('Durability'))\n",
        "df = df.withColumn(\"damage\", col('Speed') + col('Power') + col('Combat'))\n",
        "df_cp = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LbcsPTLj7dfd"
      },
      "outputs": [],
      "source": [
        "df_team_name = df.groupBy(df.group_number).max('avg_total').withColumnRenamed('max(avg_total)', 'avg_total')\n",
        "df_result = df_team_name.join(df,['group_number', 'avg_total'], 'left').select('group_number' , 'Name').withColumnRenamed('Name', 'team_name').drop_duplicates(['group_number'])\n",
        "del df_team_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lPGDstrF_ivj"
      },
      "outputs": [],
      "source": [
        "df_leader = df.groupBy(df.group_number).max('Intelligence').withColumnRenamed('max(Intelligence)', 'Intelligence')\n",
        "df_tmp = df_leader.join(df,['group_number', 'Intelligence'], 'left').select('group_number' , 'Name').withColumnRenamed('Name', 'leader').drop_duplicates(['group_number'])\n",
        "df_result = df_result.join(df_tmp, 'group_number')\n",
        "\n",
        "df = df.join(df_tmp, df.Name == df_tmp.leader, 'leftanti')\n",
        "del df_leader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BO5Qb7k5ZIMR"
      },
      "outputs": [],
      "source": [
        "df_tank = df.groupBy(df.group_number).max('tankiness').withColumnRenamed('max(tankiness)', 'tankiness')\n",
        "df_tmp = df_tank.join(df,['group_number', 'tankiness'], 'left').select('group_number' , 'Name').withColumnRenamed('Name', 'tank').drop_duplicates(['group_number'])\n",
        "df_result = df_result.join(df_tmp, 'group_number')\n",
        "\n",
        "df = df.join(df_tmp, df.Name == df_tmp.tank, 'leftanti')\n",
        "del df_tank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GyrxC0Cjc3SJ"
      },
      "outputs": [],
      "source": [
        "df_damage = df.groupBy(df.group_number).max('damage').withColumnRenamed('max(damage)', 'damage')\n",
        "df_tmp = df_damage.join(df,['group_number', 'damage'], 'left').select('group_number' , 'Name').withColumnRenamed('Name', 'damage').drop_duplicates(['group_number'])\n",
        "df_result = df_result.join(df_tmp, 'group_number')\n",
        "\n",
        "df = df.join(df_tmp, df.Name == df_tmp.damage, 'leftanti')\n",
        "del df_damage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "amCUByL2exu3"
      },
      "outputs": [],
      "source": [
        "df_other = df.groupBy(df.group_number).max('Height').withColumnRenamed('max(Height)', 'Height')\n",
        "df_tmp = df_other.join(df,['group_number', 'Height'], 'left').select('group_number', 'Name').withColumnRenamed('Name', 'other_guy_1').drop_duplicates(['group_number'])\n",
        "df_result = df_result.join(df_tmp, 'group_number')\n",
        "df = df.join(df_tmp, df.Name == df_tmp.other_guy_1, 'leftanti')\n",
        "del df_other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8vCmZCGtgQfO"
      },
      "outputs": [],
      "source": [
        "df_tmp = df.select('Name', 'group_number').withColumnRenamed('Name', 'other_guy_2')\n",
        "df_result = df_result.join(df_tmp, 'group_number')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1aOQgPwYhpO2"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import concat, col, lit\n",
        "\n",
        "df_result = df_result.withColumn('team_name',  concat(lit(\"Team: {\"), col(\"team_name\"), lit(\"}\")))\n",
        "df = df_cp\n",
        "del df_cp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tCMUUY6LFcCF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col, row_number\n",
        "window_speed = Window.partitionBy(\"group_number\").orderBy(col(\"speed\").desc())\n",
        "window_height = Window.partitionBy(\"group_number\").orderBy(col(\"height\").desc())\n",
        "\n",
        "df_tmp = df.withColumn(\"row\",row_number().over(window_speed)).filter(col(\"row\") <= 3)\n",
        "top_average_speed_df = df_tmp.groupBy(\"group_number\").avg(\"Speed\").withColumnRenamed(\"avg(Speed)\", \"top_average_speed\")\n",
        "df_result = df_result.join(top_average_speed_df, 'group_number')\n",
        "\n",
        "\n",
        "df_tmp = df.withColumn(\"row\",row_number().over(window_height)).filter(col(\"row\") <= 3)\n",
        "top_average_height_df = df_tmp.groupBy(\"group_number\").avg(\"Height\").withColumnRenamed(\"avg(Height)\", \"top_average_height\")\n",
        "df_result = df_result.join(top_average_height_df, 'group_number')\n",
        "\n",
        "del window_speed\n",
        "del window_height\n",
        "del df_tmp\n",
        "del top_average_speed_df\n",
        "del top_average_height_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PyX4nMzXyHqs"
      },
      "outputs": [],
      "source": [
        "df_flight = df.groupBy(df.group_number).sum('Flight').withColumnRenamed('sum(Flight)', 'flight_count')\n",
        "df_result = df_result.join(df_flight, 'group_number')\n",
        "del df_flight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vK7lkM3JO4dm"
      },
      "outputs": [],
      "source": [
        "# df_result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8mm8oPDhpRzb"
      },
      "outputs": [],
      "source": [
        "df_result.write.csv('result_1.csv', mode='overwrite', header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZxEY-Dobqvl"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "**ბონუს ნაწილი (2 ქულა)**\n",
        "\n",
        "ეს ნაწილიც თქვენთვის ნაცნობია და გუნდების ერთმანეთთან შეჯიბრებას, ბოლოს კი გამარჯვებულის გამოვლენას ეხება.\n",
        "შეგახსენებთ პირობას:\n",
        "\n",
        "After generating teams, obvious next task would be to perform basketball face off between teams. To determine winning teams we'll be using following logic:\n",
        "* team scores 1 point if their top_average_speed is superior \n",
        "* team scores 1 point if their top_average_height is superior \n",
        "* team scores 1 point for each member inside team who can fly (available in superheroes_power_matrix)  \n",
        "team with highest score wins!\n",
        "\n",
        "Based on rules above you should perform competition: first you'll need to randomly divide teams (all of them) into 4 brackets and generate data frames for each of them, data frame should contain all possible combinations of teams,\n",
        "for example if bracket consists of teams [A,B,C,D] data frame should contain pairs (A,B) (A,C) (A,D) (B,C) (B,D) (C,D) with following schema\n",
        "- team_a: name for first team\n",
        "- team_b: name for second team\n",
        "- team_a_score: score for first team against second team, calculated using rules described above\n",
        "- team_b_score: same for second team  \n",
        "\n",
        "after generating data frame, pick one team from each bracket with most wins: team1, team2, team3 and team4\n",
        "perform semi-finals: team1 vs team2, team3 vs team4 and finals with winner from these games\n",
        "\n",
        "**if you get a tie at any point when facing teams with each other, you can pick any team, you may also drop some teams if there is too much missing data**  \n",
        "\n",
        "---\n",
        "\n",
        "გაწვდით 3 ფაილს, რომელიც ამ დავალებისთვის დაგჭირდებათ. ფაილებში პერსონაჟები არ დუბლირდება და შეგიძლიათ, ეგ არ შეამოწმოთ.\n",
        "\n",
        "ამოხსნა ატვირთეთ ნოუთბუქის სახით.\n",
        "\n",
        "წარმატებები!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1nR4lOggqtPu"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.8-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "# import findspark\n",
        "# findspark.init()\n",
        "\n",
        "\n",
        "# from pyspark.sql import SparkSession\n",
        "# spark = SparkSession.builder.master(\"local[*]\").appName(\"Test Setup\").getOrCreate()\n",
        "# sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = spark.read.option(\"header\", True).csv(\"result_1.csv\")"
      ],
      "metadata": {
        "id": "PCB-TzAYHlW8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "j7oShtjeqJ1Q"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "df_result = df_result.select(\"group_number\", \"team_name\", \"top_average_speed\", \"top_average_height\", \"flight_count\")\n",
        "\n",
        "df_result = df_result.withColumn(\"group_number\", df_result.group_number.cast(IntegerType()))\\\n",
        "  .withColumn(\"team_name\", df_result.team_name.cast(StringType()))\\\n",
        "  .withColumn(\"top_average_speed\", df_result.top_average_speed.cast(DoubleType()))\\\n",
        "  .withColumn(\"top_average_height\", df_result.top_average_height.cast(DoubleType()))\\\n",
        "  .withColumn(\"flight_count\", df_result.flight_count.cast(IntegerType()))\n",
        "\n",
        "df_result_cp = df_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BzoOAWFhcd_H"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "count = df_result.count()\n",
        "bracket_num = ceil(count / 4)\n",
        "\n",
        "bracket_1 = df_result.limit(bracket_num)\n",
        "df_result = df_result.subtract(bracket_1)\n",
        "df_result = df_result.orderBy(\"group_number\")\n",
        "\n",
        "bracket_2 = df_result.limit(bracket_num)\n",
        "df_result = df_result.subtract(bracket_2)\n",
        "df_result = df_result.orderBy(\"group_number\")\n",
        "\n",
        "bracket_3 = df_result.limit(bracket_num)\n",
        "df_result = df_result.subtract(bracket_3)\n",
        "df_result = df_result.orderBy(\"group_number\")\n",
        "\n",
        "bracket_4 = df_result.limit(bracket_num)\n",
        "df_result = df_result.subtract(bracket_4)\n",
        "del df_result\n",
        "del count\n",
        "del bracket_num"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bracket_1_1 = bracket_1.withColumnRenamed(\"group_number\", \"group_number_1\")\\\n",
        "  .withColumnRenamed(\"team_name\", \"team_name_1\")\\\n",
        "  .withColumnRenamed(\"top_average_speed\", \"top_average_speed_1\")\\\n",
        "  .withColumnRenamed(\"top_average_height\", \"top_average_height_1\")\\\n",
        "  .withColumnRenamed(\"flight_count\", \"flight_count_1\")\n",
        "\n",
        "bracket_2_1 = bracket_2.withColumnRenamed(\"group_number\", \"group_number_1\")\\\n",
        "  .withColumnRenamed(\"team_name\", \"team_name_1\")\\\n",
        "  .withColumnRenamed(\"top_average_speed\", \"top_average_speed_1\")\\\n",
        "  .withColumnRenamed(\"top_average_height\", \"top_average_height_1\")\\\n",
        "  .withColumnRenamed(\"flight_count\", \"flight_count_1\")\n",
        "\n",
        "bracket_3_1 = bracket_3.withColumnRenamed(\"group_number\", \"group_number_1\")\\\n",
        "  .withColumnRenamed(\"team_name\", \"team_name_1\")\\\n",
        "  .withColumnRenamed(\"top_average_speed\", \"top_average_speed_1\")\\\n",
        "  .withColumnRenamed(\"top_average_height\", \"top_average_height_1\")\\\n",
        "  .withColumnRenamed(\"flight_count\", \"flight_count_1\")\n",
        "\n",
        "bracket_4_1 = bracket_4.withColumnRenamed(\"group_number\", \"group_number_1\")\\\n",
        "  .withColumnRenamed(\"team_name\", \"team_name_1\")\\\n",
        "  .withColumnRenamed(\"top_average_speed\", \"top_average_speed_1\")\\\n",
        "  .withColumnRenamed(\"top_average_height\", \"top_average_height_1\")\\\n",
        "  .withColumnRenamed(\"flight_count\", \"flight_count_1\")\n",
        "bracket_1 = bracket_1.crossJoin(bracket_1_1)\n",
        "bracket_2 = bracket_2.crossJoin(bracket_2_1)\n",
        "bracket_3 = bracket_3.crossJoin(bracket_3_1)\n",
        "bracket_4 = bracket_4.crossJoin(bracket_4_1)\n",
        "\n",
        "del bracket_1_1\n",
        "del bracket_2_1\n",
        "del bracket_3_1\n",
        "del bracket_4_1"
      ],
      "metadata": {
        "id": "87a6CdD061X4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf, col, when\n",
        "\n",
        "bracket_1 = bracket_1.select(\n",
        "    when(col('team_name') > col('team_name_1'), col('group_number')).otherwise(col('group_number_1')).alias('group_number'),\n",
        "    when(col('team_name') > col('team_name_1'), col('group_number_1')).otherwise(col('group_number')).alias('group_number_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('team_name')).otherwise(col('team_name_1')).alias('team_name'),\n",
        "    when(col('team_name') > col('team_name_1'), col('team_name_1')).otherwise(col('team_name')).alias('team_name_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_speed')).otherwise(col('top_average_speed_1')).alias('top_average_speed'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_speed_1')).otherwise(col('top_average_speed')).alias('top_average_speed_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_height')).otherwise(col('top_average_height_1')).alias('top_average_height'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_height_1')).otherwise(col('top_average_height')).alias('top_average_height_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('flight_count')).otherwise(col('flight_count_1')).alias('flight_count'),\n",
        "    when(col('team_name') > col('team_name_1'), col('flight_count_1')).otherwise(col('flight_count')).alias('flight_count_1')\n",
        ")\n",
        "bracket_1 = bracket_1.dropDuplicates(['team_name', 'team_name_1']).orderBy('group_number', 'group_number_1')\n",
        "bracket_1 = bracket_1.filter(bracket_1.group_number != bracket_1.group_number_1)"
      ],
      "metadata": {
        "id": "VFSFvfwjAQ19"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bracket_2 = bracket_2.select(\n",
        "    when(col('team_name') > col('team_name_1'), col('group_number')).otherwise(col('group_number_1')).alias('group_number'),\n",
        "    when(col('team_name') > col('team_name_1'), col('group_number_1')).otherwise(col('group_number')).alias('group_number_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('team_name')).otherwise(col('team_name_1')).alias('team_name'),\n",
        "    when(col('team_name') > col('team_name_1'), col('team_name_1')).otherwise(col('team_name')).alias('team_name_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_speed')).otherwise(col('top_average_speed_1')).alias('top_average_speed'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_speed_1')).otherwise(col('top_average_speed')).alias('top_average_speed_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_height')).otherwise(col('top_average_height_1')).alias('top_average_height'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_height_1')).otherwise(col('top_average_height')).alias('top_average_height_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('flight_count')).otherwise(col('flight_count_1')).alias('flight_count'),\n",
        "    when(col('team_name') > col('team_name_1'), col('flight_count_1')).otherwise(col('flight_count')).alias('flight_count_1')\n",
        ")\n",
        "bracket_2 = bracket_2.dropDuplicates(['team_name', 'team_name_1']).orderBy('group_number', 'group_number_1')\n",
        "bracket_2 = bracket_2.filter(bracket_2.group_number != bracket_2.group_number_1)"
      ],
      "metadata": {
        "id": "r7-jQkzzFJPL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bracket_3 = bracket_3.select(\n",
        "    when(col('team_name') > col('team_name_1'), col('group_number')).otherwise(col('group_number_1')).alias('group_number'),\n",
        "    when(col('team_name') > col('team_name_1'), col('group_number_1')).otherwise(col('group_number')).alias('group_number_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('team_name')).otherwise(col('team_name_1')).alias('team_name'),\n",
        "    when(col('team_name') > col('team_name_1'), col('team_name_1')).otherwise(col('team_name')).alias('team_name_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_speed')).otherwise(col('top_average_speed_1')).alias('top_average_speed'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_speed_1')).otherwise(col('top_average_speed')).alias('top_average_speed_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_height')).otherwise(col('top_average_height_1')).alias('top_average_height'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_height_1')).otherwise(col('top_average_height')).alias('top_average_height_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('flight_count')).otherwise(col('flight_count_1')).alias('flight_count'),\n",
        "    when(col('team_name') > col('team_name_1'), col('flight_count_1')).otherwise(col('flight_count')).alias('flight_count_1')\n",
        ")\n",
        "bracket_3 = bracket_3.dropDuplicates(['team_name', 'team_name_1']).orderBy('group_number', 'group_number_1')\n",
        "bracket_3 = bracket_3.filter(bracket_3.group_number != bracket_3.group_number_1)"
      ],
      "metadata": {
        "id": "mjqr5Ut1u4Ui"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bracket_4 = bracket_4.select(\n",
        "    when(col('team_name') > col('team_name_1'), col('group_number')).otherwise(col('group_number_1')).alias('group_number'),\n",
        "    when(col('team_name') > col('team_name_1'), col('group_number_1')).otherwise(col('group_number')).alias('group_number_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('team_name')).otherwise(col('team_name_1')).alias('team_name'),\n",
        "    when(col('team_name') > col('team_name_1'), col('team_name_1')).otherwise(col('team_name')).alias('team_name_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_speed')).otherwise(col('top_average_speed_1')).alias('top_average_speed'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_speed_1')).otherwise(col('top_average_speed')).alias('top_average_speed_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_height')).otherwise(col('top_average_height_1')).alias('top_average_height'),\n",
        "    when(col('team_name') > col('team_name_1'), col('top_average_height_1')).otherwise(col('top_average_height')).alias('top_average_height_1'),\n",
        "    when(col('team_name') > col('team_name_1'), col('flight_count')).otherwise(col('flight_count_1')).alias('flight_count'),\n",
        "    when(col('team_name') > col('team_name_1'), col('flight_count_1')).otherwise(col('flight_count')).alias('flight_count_1')\n",
        ")\n",
        "bracket_4 = bracket_4.dropDuplicates(['team_name', 'team_name_1']).orderBy('group_number', 'group_number_1')\n",
        "bracket_4 = bracket_4.filter(bracket_4.group_number != bracket_4.group_number_1)"
      ],
      "metadata": {
        "id": "1iX5_T5buuV7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(returnType=IntegerType())\n",
        "def calculate_score(a_flight, b_flight, a_speed, b_speed, a_height, b_height):\n",
        "    score = a_flight\n",
        "    if a_speed > b_speed:\n",
        "      score += 1\n",
        "    if a_height > b_height:\n",
        "      score += 1\n",
        "    return score"
      ],
      "metadata": {
        "id": "b97ZqMGK9gzN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bracket_1 = bracket_1.withColumn(\"team_a_score\", calculate_score(bracket_1.flight_count, bracket_1.flight_count_1, bracket_1.top_average_speed, bracket_1.top_average_speed_1, bracket_1.top_average_height, bracket_1.top_average_height_1))\n",
        "bracket_1 = bracket_1.withColumn(\"team_b_score\", calculate_score(bracket_1.flight_count_1, bracket_1.flight_count, bracket_1.top_average_speed_1, bracket_1.top_average_speed, bracket_1.top_average_height_1, bracket_1.top_average_height))\n",
        "bracket_1 = bracket_1.withColumnRenamed(\"team_name\", \"team_a\").withColumnRenamed(\"team_name_1\", \"team_b\").select(\"team_a\", \"team_b\", \"team_a_score\", \"team_b_score\")\n",
        "\n",
        "bracket_2 = bracket_2.withColumn(\"team_a_score\", calculate_score(bracket_2.flight_count, bracket_2.flight_count_1, bracket_2.top_average_speed, bracket_2.top_average_speed_1, bracket_2.top_average_height, bracket_2.top_average_height_1))\n",
        "bracket_2 = bracket_2.withColumn(\"team_b_score\", calculate_score(bracket_2.flight_count_1, bracket_2.flight_count, bracket_2.top_average_speed_1, bracket_2.top_average_speed, bracket_2.top_average_height_1, bracket_2.top_average_height))\n",
        "bracket_2 = bracket_2.withColumnRenamed(\"team_name\", \"team_a\").withColumnRenamed(\"team_name_1\", \"team_b\").select(\"team_a\", \"team_b\", \"team_a_score\", \"team_b_score\")\n",
        "\n",
        "\n",
        "bracket_3 = bracket_3.withColumn(\"team_a_score\", calculate_score(bracket_3.flight_count, bracket_3.flight_count_1, bracket_3.top_average_speed, bracket_3.top_average_speed_1, bracket_3.top_average_height, bracket_3.top_average_height_1))\n",
        "bracket_3 = bracket_3.withColumn(\"team_b_score\", calculate_score(bracket_3.flight_count_1, bracket_3.flight_count, bracket_3.top_average_speed_1, bracket_3.top_average_speed, bracket_3.top_average_height_1, bracket_3.top_average_height))\n",
        "bracket_3 = bracket_3.withColumnRenamed(\"team_name\", \"team_a\").withColumnRenamed(\"team_name_1\", \"team_b\").select(\"team_a\", \"team_b\", \"team_a_score\", \"team_b_score\")\n",
        "\n",
        "\n",
        "bracket_4 = bracket_4.withColumn(\"team_a_score\", calculate_score(bracket_4.flight_count, bracket_4.flight_count_1, bracket_4.top_average_speed, bracket_4.top_average_speed_1, bracket_4.top_average_height, bracket_4.top_average_height_1))\n",
        "bracket_4 = bracket_4.withColumn(\"team_b_score\", calculate_score(bracket_4.flight_count_1, bracket_4.flight_count, bracket_4.top_average_speed_1, bracket_4.top_average_speed, bracket_4.top_average_height_1, bracket_4.top_average_height))\n",
        "bracket_4 = bracket_4.withColumnRenamed(\"team_name\", \"team_a\").withColumnRenamed(\"team_name_1\", \"team_b\").select(\"team_a\", \"team_b\", \"team_a_score\", \"team_b_score\")"
      ],
      "metadata": {
        "id": "4vCsSsxR9qhE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@udf(returnType=StringType())\n",
        "def determine_winner(team_a, team_b, a_score, b_score):\n",
        "         return team_a if a_score > b_score else team_b "
      ],
      "metadata": {
        "id": "2qWglmC2gOLM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bracket_1 = bracket_1.withColumn(\"winner\", determine_winner(bracket_1.team_a, bracket_1.team_b, bracket_1.team_a_score, bracket_1.team_b_score))\n",
        "bracket_2 = bracket_2.withColumn(\"winner\", determine_winner(bracket_2.team_a, bracket_2.team_b, bracket_2.team_a_score, bracket_2.team_b_score))\n",
        "bracket_3 = bracket_3.withColumn(\"winner\", determine_winner(bracket_3.team_a, bracket_3.team_b, bracket_3.team_a_score, bracket_3.team_b_score))\n",
        "bracket_4 = bracket_4.withColumn(\"winner\", determine_winner(bracket_4.team_a, bracket_4.team_b, bracket_4.team_a_score, bracket_4.team_b_score))"
      ],
      "metadata": {
        "id": "U0N5dyhigwNQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "win_counts = bracket_1.groupBy(bracket_1.winner).count()\n",
        "max_wins = win_counts.groupBy().max('count').withColumnRenamed(\"max(count)\", \"count\")\n",
        "winner_team_1 = max_wins.join(win_counts, \"count\", 'inner').drop_duplicates(['count'])\n",
        "\n",
        "win_counts = bracket_2.groupBy(bracket_2.winner).count()\n",
        "max_wins = win_counts.groupBy().max('count').withColumnRenamed(\"max(count)\", \"count\")\n",
        "winner_team_2 = max_wins.join(win_counts, \"count\", 'inner').drop_duplicates(['count'])\n",
        "\n",
        "win_counts = bracket_3.groupBy(bracket_3.winner).count()\n",
        "max_wins = win_counts.groupBy().max('count').withColumnRenamed(\"max(count)\", \"count\")\n",
        "winner_team_3 = max_wins.join(win_counts, \"count\", 'inner').drop_duplicates(['count'])\n",
        "\n",
        "win_counts = bracket_4.groupBy(bracket_4.winner).count()\n",
        "max_wins = win_counts.groupBy().max('count').withColumnRenamed(\"max(count)\", \"count\")\n",
        "winner_team_4 = max_wins.join(win_counts, \"count\", 'inner').drop_duplicates(['count'])\n",
        "\n",
        "del bracket_1\n",
        "del bracket_2\n",
        "del bracket_3\n",
        "del bracket_4"
      ],
      "metadata": {
        "id": "aarC3NkAiNqo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = df_result_cp\n",
        "del df_result_cp\n",
        "winner_team_1 = winner_team_1.join(df_result, winner_team_1.winner == df_result.team_name, 'left').drop(\"count\", \"group_number\", \"winner\")\n",
        "winner_team_2 = winner_team_2.join(df_result, winner_team_2.winner == df_result.team_name, 'left').drop(\"count\", \"group_number\", \"winner\")\n",
        "winner_team_3 = winner_team_3.join(df_result, winner_team_3.winner == df_result.team_name, 'left').drop(\"count\", \"group_number\", \"winner\")\n",
        "winner_team_4 = winner_team_4.join(df_result, winner_team_4.winner == df_result.team_name, 'left').drop(\"count\", \"group_number\", \"winner\")"
      ],
      "metadata": {
        "id": "XlgeuBwOigOw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
        "from pyspark.sql import Window\n",
        "\n",
        "\n",
        "winner_team_1 = winner_team_1.withColumn(\"row_id\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "winner_team_2 = winner_team_2.withColumn(\"row_id\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "winner_team_2 = winner_team_2.withColumnRenamed(\"team_name\", \"team_name_1\")\\\n",
        "  .withColumnRenamed(\"top_average_speed\", \"top_average_speed_1\")\\\n",
        "  .withColumnRenamed(\"top_average_height\", \"top_average_height_1\")\\\n",
        "  .withColumnRenamed(\"flight_count\", \"flight_count_1\")\n",
        "semifinal_1 = winner_team_1.join(winner_team_2, \"row_id\", \"left\").drop(\"row_id\")\n",
        "\n",
        "\n",
        "\n",
        "winner_team_3 = winner_team_3.withColumn(\"row_id\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "winner_team_4 = winner_team_4.withColumn(\"row_id\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "winner_team_4 = winner_team_4.withColumnRenamed(\"team_name\", \"team_name_1\")\\\n",
        "  .withColumnRenamed(\"top_average_speed\", \"top_average_speed_1\")\\\n",
        "  .withColumnRenamed(\"top_average_height\", \"top_average_height_1\")\\\n",
        "  .withColumnRenamed(\"flight_count\", \"flight_count_1\")\n",
        "semifinal_2 = winner_team_3.join(winner_team_4, \"row_id\", \"left\").drop(\"row_id\")\n",
        "\n",
        "del winner_team_1\n",
        "del winner_team_2\n",
        "del winner_team_3\n",
        "del winner_team_4"
      ],
      "metadata": {
        "id": "A3sCZ4Q42qbX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semifinal_1 = semifinal_1.withColumn(\"team_a_score\", calculate_score(semifinal_1.flight_count, semifinal_1.flight_count_1, semifinal_1.top_average_speed, semifinal_1.top_average_speed_1, semifinal_1.top_average_height, semifinal_1.top_average_height_1))\n",
        "semifinal_1 = semifinal_1.withColumn(\"team_b_score\", calculate_score(semifinal_1.flight_count_1, semifinal_1.flight_count, semifinal_1.top_average_speed_1, semifinal_1.top_average_speed, semifinal_1.top_average_height_1, semifinal_1.top_average_height))\n",
        "semifinal_1 = semifinal_1.withColumnRenamed(\"team_name\", \"team_a\").withColumnRenamed(\"team_name_1\", \"team_b\").select(\"team_a\", \"team_b\", \"team_a_score\", \"team_b_score\")\n",
        "\n",
        "semifinal_2 = semifinal_2.withColumn(\"team_a_score\", calculate_score(semifinal_2.flight_count, semifinal_2.flight_count_1, semifinal_2.top_average_speed, semifinal_2.top_average_speed_1, semifinal_2.top_average_height, semifinal_2.top_average_height_1))\n",
        "semifinal_2 = semifinal_2.withColumn(\"team_b_score\", calculate_score(semifinal_2.flight_count_1, semifinal_2.flight_count, semifinal_2.top_average_speed_1, semifinal_2.top_average_speed, semifinal_2.top_average_height_1, semifinal_2.top_average_height))\n",
        "semifinal_2 = semifinal_2.withColumnRenamed(\"team_name\", \"team_a\").withColumnRenamed(\"team_name_1\", \"team_b\").select(\"team_a\", \"team_b\", \"team_a_score\", \"team_b_score\")"
      ],
      "metadata": {
        "id": "KAccAKcY5H-4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semifinal_1 = semifinal_1.withColumn(\"winner\", determine_winner(semifinal_1.team_a, semifinal_1.team_b, semifinal_1.team_a_score, semifinal_1.team_b_score))\n",
        "semifinal_2 = semifinal_2.withColumn(\"winner\", determine_winner(semifinal_2.team_a, semifinal_2.team_b, semifinal_2.team_a_score, semifinal_2.team_b_score))"
      ],
      "metadata": {
        "id": "aGJpnpEn_Q-n"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semifinal_1_winner = semifinal_1.select(\"winner\")\n",
        "semifinal_2_winner = semifinal_2.select(\"winner\")\n",
        "del semifinal_1\n",
        "del semifinal_2"
      ],
      "metadata": {
        "id": "LzpBK63c_gji"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semifinal_1_winner = semifinal_1_winner.join(df_result, semifinal_1_winner.winner == df_result.team_name, 'left').drop(\"group_number\", \"winner\")\n",
        "semifinal_2_winner = semifinal_2_winner.join(df_result, semifinal_2_winner.winner == df_result.team_name, 'left').drop(\"group_number\", \"winner\")"
      ],
      "metadata": {
        "id": "q0T7awsF_h8q"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semifinal_1_winner = semifinal_1_winner.withColumn(\"row_id\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "semifinal_2_winner = semifinal_2_winner.withColumn(\"row_id\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "semifinal_2_winner = semifinal_2_winner.withColumnRenamed(\"team_name\", \"team_name_1\")\\\n",
        "  .withColumnRenamed(\"top_average_speed\", \"top_average_speed_1\")\\\n",
        "  .withColumnRenamed(\"top_average_height\", \"top_average_height_1\")\\\n",
        "  .withColumnRenamed(\"flight_count\", \"flight_count_1\")\n",
        "final = semifinal_1_winner.join(semifinal_2_winner, \"row_id\", \"left\").drop(\"row_id\")\n",
        "del semifinal_1_winner\n",
        "del semifinal_2_winner"
      ],
      "metadata": {
        "id": "zLCMqJwzBVDp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = final.withColumn(\"team_a_score\", calculate_score(final.flight_count, final.flight_count_1, final.top_average_speed, final.top_average_speed_1, final.top_average_height, final.top_average_height_1))\n",
        "final = final.withColumn(\"team_b_score\", calculate_score(final.flight_count_1, final.flight_count, final.top_average_speed_1, final.top_average_speed, final.top_average_height_1, final.top_average_height))\n",
        "final = final.withColumnRenamed(\"team_name\", \"team_a\").withColumnRenamed(\"team_name_1\", \"team_b\").select(\"team_a\", \"team_b\", \"team_a_score\", \"team_b_score\")"
      ],
      "metadata": {
        "id": "quPbeyOgB51_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = final.withColumn(\"winner\", determine_winner(final.team_a, final.team_b, final.team_a_score, final.team_b_score))\n",
        "# final.show()"
      ],
      "metadata": {
        "id": "9v-bf7QfCAr5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.write.csv('result_2.csv', mode='overwrite', header=True)"
      ],
      "metadata": {
        "id": "w1fjjaNcEywl"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_winner = final.select(\"winner\")\n",
        "# final_winner.show()\n",
        "# del final_winner\n",
        "\n",
        "del final"
      ],
      "metadata": {
        "id": "2t3uE32EC7vs"
      },
      "execution_count": 49,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment_4_Spark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}